{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.412727Z",
     "iopub.status.busy": "2025-02-18T22:20:44.412265Z",
     "iopub.status.idle": "2025-02-18T22:20:44.418570Z",
     "shell.execute_reply": "2025-02-18T22:20:44.417113Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.412680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.421148Z",
     "iopub.status.busy": "2025-02-18T22:20:44.420664Z",
     "iopub.status.idle": "2025-02-18T22:20:44.442475Z",
     "shell.execute_reply": "2025-02-18T22:20:44.441230Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.421102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install pyloudnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\katja\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Downloading numba-0.61.0-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/2.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/30.3 MB 8.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.1/30.3 MB 7.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.5/30.3 MB 7.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.0/30.3 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 7.9/30.3 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 9.4/30.3 MB 7.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 10.7/30.3 MB 7.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 11.8/30.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 13.1/30.3 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 14.7/30.3 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 16.0/30.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 17.0/30.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 18.4/30.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 19.7/30.3 MB 6.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 21.0/30.3 MB 6.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 22.0/30.3 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 23.1/30.3 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 24.1/30.3 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 25.4/30.3 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 27.0/30.3 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.3/30.3 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.6/30.3 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: soxr, pycparser, msgpack, llvmlite, lazy-loader, audioread, pooch, numba, cffi, soundfile, librosa\n",
      "Successfully installed audioread-3.0.1 cffi-1.17.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.0 pooch-1.8.2 pycparser-2.22 soundfile-0.13.1 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "# !pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.445340Z",
     "iopub.status.busy": "2025-02-18T22:20:44.444960Z",
     "iopub.status.idle": "2025-02-18T22:20:44.458348Z",
     "shell.execute_reply": "2025-02-18T22:20:44.457206Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.445311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "from glob import glob\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal, linalg\n",
    "import sklearn\n",
    "from ipywidgets import interact\n",
    "import urllib\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pyloudnorm as pyln\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.460250Z",
     "iopub.status.busy": "2025-02-18T22:20:44.459853Z",
     "iopub.status.idle": "2025-02-18T22:20:44.478955Z",
     "shell.execute_reply": "2025-02-18T22:20:44.477528Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.460223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_vad_model():\n",
    "    model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')\n",
    "    speech_timestamps = utils[0]\n",
    "    read_audio = utils[2]\n",
    "    \n",
    "    return speech_timestamps, model, read_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.480836Z",
     "iopub.status.busy": "2025-02-18T22:20:44.480385Z",
     "iopub.status.idle": "2025-02-18T22:20:44.504174Z",
     "shell.execute_reply": "2025-02-18T22:20:44.502795Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.480792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pyloudnorm as pyln\n",
    "import numpy as np\n",
    "\n",
    "def loudness_normalization(audio, target_lufs=-23.0):\n",
    "    meter = pyln.Meter(16000)\n",
    "    loudness = meter.integrated_loudness(audio)\n",
    "    gain = target_lufs - loudness\n",
    "    \n",
    "    normalized_audio = audio * (10**(gain / 20))\n",
    "    \n",
    "    return normalized_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.506152Z",
     "iopub.status.busy": "2025-02-18T22:20:44.505666Z",
     "iopub.status.idle": "2025-02-18T22:20:44.526211Z",
     "shell.execute_reply": "2025-02-18T22:20:44.524636Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.506105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_filters(audio, sr):\n",
    "    hp_cutoff = 80 \n",
    "    b, a = signal.butter(4, hp_cutoff / (sr / 2), btype='highpass')\n",
    "    audio = signal.filtfilt(b, a, audio)\n",
    "\n",
    "    lp_cutoff = 7000\n",
    "    b, a = signal.butter(4, lp_cutoff / (sr / 2), btype='lowpass')\n",
    "    audio = signal.filtfilt(b, a, audio)\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:20:44.528073Z",
     "iopub.status.busy": "2025-02-18T22:20:44.527732Z",
     "iopub.status.idle": "2025-02-18T22:20:44.547072Z",
     "shell.execute_reply": "2025-02-18T22:20:44.545711Z",
     "shell.execute_reply.started": "2025-02-18T22:20:44.528033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_silero_vad(audio, speech_timestamps, model):\n",
    "    audio_tensor = torch.tensor(audio, dtype=torch.float32)\n",
    "    \n",
    "    speech_segments = get_speech_timestamps(\n",
    "        audio_tensor,\n",
    "        model,\n",
    "        return_seconds=False\n",
    "    )\n",
    "    return speech_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:24:54.436180Z",
     "iopub.status.busy": "2025-02-18T22:24:54.435764Z",
     "iopub.status.idle": "2025-02-18T22:24:54.444025Z",
     "shell.execute_reply": "2025-02-18T22:24:54.442613Z",
     "shell.execute_reply.started": "2025-02-18T22:24:54.436152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_features(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio)\n",
    "\n",
    "    spectral_flux = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    spectral_flux = spectral_flux.reshape(1, -1)\n",
    "\n",
    "    ste = librosa.feature.rms(y=audio)\n",
    "\n",
    "    # spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)\n",
    "\n",
    "    # spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "\n",
    "    # spectral_flatness = librosa.feature.spectral_flatness(y=audio)\n",
    "    \n",
    "    # features_list = [mfccs, spectral_centroid, zcr, spectral_flux, ste, spectral_rolloff, spectral_bandwidth, spectral_flatness]\n",
    "    features_list = [mfccs, spectral_centroid, zcr, spectral_flux, ste]\n",
    "\n",
    "    num_frames = min(f.shape[1] for f in features_list)\n",
    "    \n",
    "    features = np.vstack([f[:, :num_frames] for f in features_list]).T\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:24:25.042870Z",
     "iopub.status.busy": "2025-02-18T22:24:25.042531Z",
     "iopub.status.idle": "2025-02-18T22:24:25.048298Z",
     "shell.execute_reply": "2025-02-18T22:24:25.046963Z",
     "shell.execute_reply.started": "2025-02-18T22:24:25.042845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features, method=\"standard\"):\n",
    "    if method == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif method == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "    return scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:24:57.604107Z",
     "iopub.status.busy": "2025-02-18T22:24:57.603666Z",
     "iopub.status.idle": "2025-02-18T22:24:57.614664Z",
     "shell.execute_reply": "2025-02-18T22:24:57.613316Z",
     "shell.execute_reply.started": "2025-02-18T22:24:57.604076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_audio_file(audio_path, speech_timestamps, model, sr=16000, chunk_duration=0.025):\n",
    "    audio, sr = librosa.load(audio_path, sr=sr, mono=True)\n",
    "\n",
    "    audio = apply_filters(audio, sr)\n",
    "    audio = loudness_normalization(audio)\n",
    "    \n",
    "    speech_segments = apply_silero_vad(audio, get_speech_timestamps, model)\n",
    "\n",
    "    features = extract_features(audio, sr)\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(features.shape[0]):\n",
    "        chunk_start = int(i * chunk_duration * sr)\n",
    "        chunk_end = chunk_start + int(chunk_duration * sr)\n",
    "\n",
    "        is_speech = any(s['start'] <= chunk_start and s['end'] >= chunk_end for s in speech_segments)\n",
    "        labels.append(1 if is_speech else 0)\n",
    "\n",
    "    if len(labels) != features.shape[0]:\n",
    "        if len(labels) > features.shape[0]:\n",
    "            labels = labels[:features.shape[0]]\n",
    "        else:\n",
    "            labels.extend([0] * (features.shape[0] - len(labels)))\n",
    "\n",
    "    features = normalize_features(features, method=\"standard\")\n",
    "\n",
    "    num_features = features.shape[1]\n",
    "    feature_names = [f\"feature_{i}\" for i in range(num_features)]\n",
    "\n",
    "    df = pd.DataFrame(features, columns=feature_names)\n",
    "    df[\"vad_label\"] = labels\n",
    "    df[\"start_time\"] = [(i * chunk_duration) for i in range(len(labels))]\n",
    "    df[\"end_time\"] = [((i + 1) * chunk_duration) for i in range(len(labels))]\n",
    "    df[\"file_path\"] = audio_path\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:25:00.333981Z",
     "iopub.status.busy": "2025-02-18T22:25:00.333614Z",
     "iopub.status.idle": "2025-02-18T22:25:33.668547Z",
     "shell.execute_reply": "2025-02-18T22:25:33.667484Z",
     "shell.execute_reply.started": "2025-02-18T22:25:00.333955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\katja/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "def process_directory(input_dir, output_csv, get_speech_timestamps, model):\n",
    "\n",
    "    all_data = []  \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith(\".wav\"): \n",
    "                audio_path = os.path.join(root, file)\n",
    "                \n",
    "                try:\n",
    "                    df = process_audio_file(audio_path, get_speech_timestamps, model)\n",
    "                    all_data.append(df)\n",
    "                    processed_count += 1\n",
    "                    \n",
    "                    if processed_count % 100 == 0:\n",
    "                        intermediate_df = pd.concat(all_data, ignore_index=True)\n",
    "                        intermediate_df.to_csv(f\"{output_csv}.intermediate_{processed_count}\", index=False)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df.to_csv(output_csv, index=False)\n",
    "\n",
    "\n",
    "input_directory = \"/kaggle/input/english-multispeaker-corpus-for-voice-cloning/VCTK-Corpus/VCTK-Corpus/wav48/p225\"\n",
    "output_csv_path = \"output_features.csv\"\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "get_speech_timestamps, model, read_audio = load_vad_model()\n",
    "\n",
    "process_directory(input_directory, output_csv_path, get_speech_timestamps, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T22:25:36.707388Z",
     "iopub.status.busy": "2025-02-18T22:25:36.706944Z",
     "iopub.status.idle": "2025-02-18T22:25:37.333605Z",
     "shell.execute_reply": "2025-02-18T22:25:37.332396Z",
     "shell.execute_reply.started": "2025-02-18T22:25:36.707356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/output_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 70\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 48\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     47\u001b[0m     csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/output_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 48\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     feature_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvad_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     52\u001b[0m     features \u001b[38;5;241m=\u001b[39m df[feature_columns]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\katja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\katja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\katja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\katja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\katja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/output_features.csv'"
     ]
    }
   ],
   "source": [
    "def align_cluster_labels(cluster_labels, vad_labels):\n",
    "    if set(np.unique(cluster_labels)).issubset({0, 1, -1}):\n",
    "        non_noise_mask = cluster_labels != -1\n",
    "        filtered_clusters = cluster_labels[non_noise_mask]\n",
    "        filtered_vad = vad_labels[non_noise_mask]\n",
    "        \n",
    "        if len(filtered_clusters) == 0:\n",
    "            return np.zeros_like(cluster_labels)\n",
    "            \n",
    "        contingency = pd.crosstab(filtered_clusters, filtered_vad)\n",
    "        \n",
    "        if 0 in contingency.index and 1 in contingency.index:\n",
    "            if contingency.loc[0, 1] > contingency.loc[1, 1]:\n",
    "               \n",
    "                mapping = {0: 1, 1: 0, -1: 0} \n",
    "            else:\n",
    "                mapping = {0: 0, 1: 1, -1: 0}  \n",
    "        else:\n",
    "            only_label = list(contingency.index)[0]\n",
    "            if contingency.loc[only_label, 1] > contingency.loc[only_label, 0]:\n",
    "                mapping = {only_label: 1, -1: 0}\n",
    "            else:\n",
    "                mapping = {only_label: 0, -1: 0}\n",
    "    \n",
    "    labels = np.array([mapping.get(l, 0) for l in cluster_labels])\n",
    "    return labels\n",
    "\n",
    "def evaluate_clustering(vad_labels, cluster_labels):\n",
    "    aligned_labels = align_cluster_labels(cluster_labels, vad_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(vad_labels, aligned_labels)\n",
    "    precision = precision_score(vad_labels, aligned_labels, zero_division=0)\n",
    "    recall = recall_score(vad_labels, aligned_labels, zero_division=0)\n",
    "    f1 = f1_score(vad_labels, aligned_labels, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(vad_labels, aligned_labels)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'aligned_labels': aligned_labels\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    csv_file = \"/kaggle/working/output_features.csv\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    feature_columns = [col for col in df.columns if col not in ['vad_label', 'start_time', 'end_time', 'file_path']]\n",
    "    \n",
    "    features = df[feature_columns].values\n",
    "    vad_labels = df['vad_label'].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    kmeans_labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    results = evaluate_clustering(vad_labels, kmeans_labels)\n",
    "    \n",
    "    print(\"Evaluation Results for KMeans Clustering:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results['f1_score']:.4f}\")\n",
    "    \n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 212383,
     "sourceId": 847347,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
